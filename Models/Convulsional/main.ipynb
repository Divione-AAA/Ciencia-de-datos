{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0836be77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\vpn\\Documents\\GitHub\\Ciencia-de-datos\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense,InputLayer, Conv2D, MaxPooling2D, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7d15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset ya dividido en train/val/test usando el parámetro split de TFDS\n",
    "(train, val, test), data_info = tfds.load(\"malaria\",with_info=True,\n",
    "                                        split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "                                        shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47232e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='malaria',\n",
       "    full_name='malaria/1.0.0',\n",
       "    description=\"\"\"\n",
       "    The Malaria dataset contains a total of 27,558 cell images with equal instances\n",
       "    of parasitized and uninfected cells from the thin blood smear slide images of\n",
       "    segmented cells.\n",
       "    \"\"\",\n",
       "    homepage='https://lhncbc.nlm.nih.gov/publication/pub9932',\n",
       "    data_dir='C:\\\\Users\\\\vpn\\\\tensorflow_datasets\\\\malaria\\\\1.0.0',\n",
       "    file_format=tfrecord,\n",
       "    download_size=337.08 MiB,\n",
       "    dataset_size=317.62 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(None, None, 3), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=2),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    nondeterministic_order=False,\n",
       "    splits={\n",
       "        'train': <SplitInfo num_examples=27558, num_shards=4>,\n",
       "    },\n",
       "    citation=\"\"\"@article{rajaraman2018pre,\n",
       "      title={Pre-trained convolutional neural networks as feature extractors toward\n",
       "      improved malaria parasite detection in thin blood smear images},\n",
       "      author={Rajaraman, Sivaramakrishnan and Antani, Sameer K and Poostchi, Mahdieh\n",
       "      and Silamut, Kamolrat and Hossain, Md A and Maude, Richard J and Jaeger,\n",
       "      Stefan and Thoma, George R},\n",
       "      journal={PeerJ},\n",
       "      volume={6},\n",
       "      pages={e4568},\n",
       "      year={2018},\n",
       "      publisher={PeerJ Inc.}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e90a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_only(example):\n",
    "    image = example['image']\n",
    "    label = example['label']\n",
    "    # Redimensionar\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    # Normalizar (opcional pero recomendado)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = (train\n",
    "                .map(resize_only, num_parallel_calls=AUTOTUNE)\n",
    "                .batch(32)\n",
    "                .prefetch(AUTOTUNE))\n",
    "\n",
    "val_dataset = (val\n",
    "                .map(resize_only, num_parallel_calls=AUTOTUNE)\n",
    "                .batch(32)\n",
    "                .prefetch(AUTOTUNE))\n",
    "\n",
    "test_dataset = (test\n",
    "                .map(resize_only, num_parallel_calls=AUTOTUNE)\n",
    "                .batch(32)\n",
    "                .prefetch(AUTOTUNE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f85eeded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos el modelo CNN\n",
    "model = models.Sequential([\n",
    "    # Entrada\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    #Bloque 1\n",
    "    layers.Conv2D(10, (3,3), strides=1, padding='same',\n",
    "                activation='relu', use_bias=True, name='conv1'),\n",
    "    layers.Conv2D(10, (3,3), strides=1, padding='same',\n",
    "                activation='relu', use_bias=True, name='conv2'),\n",
    "    layers.MaxPooling2D((2,2), name='pool1'),#Reduce resolucion a la mitad\n",
    "    # Bloque 2\n",
    "    layers.Conv2D(10, (3,3), strides=1, padding='same',\n",
    "                activation='relu', use_bias=True, name='conv3'),\n",
    "    layers.Conv2D(10, (3,3), strides=1, padding='same',\n",
    "                activation='relu', use_bias=True, name='conv4'),\n",
    "    layers.MaxPooling2D((2,2), name='pool2'),#Reduce resolucion a la mitad\n",
    "    #Reducción y capa densa\n",
    "    layers.GlobalAveragePooling2D(name='gap'), #Promedia cada mapa en un vector de tamaño (batch_size, n_classes)\n",
    "    layers.Dense(128, activation='relu', use_bias=True, name='fc1'),#Capa densa de 128 neyronas que procesa el vector de salida del gap\n",
    "    layers.Dropout(0.3, name='dropout'),#Se apagan algunas neuronas el 30% en entrenamiento se encienden\n",
    "    #Capa de salida (softmax porque es una clasificación)\n",
    "    layers.Dense(2, activation='softmax', use_bias=True, name='output')\n",
    "])\n",
    "\n",
    "#Compilacion del modelo\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "            loss='sparse_categorical_crossentropy',   # porque las etiquetas son enteros 0/1\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b24ffd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 224, 224, 10)      280       \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 224, 224, 10)      910       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 112, 112, 10)      0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 112, 112, 10)      910       \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 112, 112, 10)      910       \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 56, 56, 10)        0         \n",
      "                                                                 \n",
      " gap (GlobalAveragePooling2  (None, 10)                0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               1408      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4676 (18.27 KB)\n",
      "Trainable params: 4676 (18.27 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento\n",
    "model.fit(\n",
    "  train_dataset,\n",
    "  validation_data = val_dataset,\n",
    "  epochs = 20,\n",
    "  callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint('best_malaria_cnn.h5', save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bad12d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 5s 52ms/step - loss: 0.1371 - accuracy: 0.9586\n",
      "Exactitud en test: 0.959\n"
     ]
    }
   ],
   "source": [
    "#Acuracy\n",
    "save = load_model(\"best_malaria_cnn.h5\")\n",
    "test_loss, test_acc = save.evaluate(test_dataset)\n",
    "print(f\"Exactitud en test: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ecc789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "Predicción: [[0.12280191 0.87719804]]\n",
      "Etiqueta real: 1\n"
     ]
    }
   ],
   "source": [
    "# Tomar un batch del dataset\n",
    "example_batch = next(iter(test_dataset.take(1)))\n",
    "\n",
    "# Extraer una sola imagen (posición 0)\n",
    "img = example_batch[0][0]  # primera imagen del batch\n",
    "label = example_batch[1][0]  # su etiqueta\n",
    "\n",
    "# Redimensionar y normalizar\n",
    "img = tf.image.resize(img, (224, 224)) / 255.0\n",
    "img = tf.expand_dims(img, axis=0)  # añadir dimensión batch\n",
    "\n",
    "# Predicción\n",
    "pred = save.predict(img)\n",
    "print(\"Predicción:\", pred)\n",
    "print(\"Etiqueta real:\", label.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
