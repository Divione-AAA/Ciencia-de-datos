{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf35f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.integration.keras import WandbCallback\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c35f878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3df306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, val, test), data_info = tfds.load(\"malaria\",with_info=True,\n",
    "                                        split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "                                        shuffle_files=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6088db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_only(image, label):\n",
    "    # Redimensionar\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    # Normalizar (opcional pero recomendado)\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = (train\n",
    "                .map(resize_only, num_parallel_calls=AUTOTUNE)\n",
    "                .batch(32)\n",
    "                .prefetch(AUTOTUNE))\n",
    "\n",
    "val_dataset = (val\n",
    "                .map(resize_only, num_parallel_calls=AUTOTUNE)\n",
    "                .batch(32)\n",
    "                .prefetch(AUTOTUNE))\n",
    "\n",
    "test_dataset = (test\n",
    "                .map(resize_only, num_parallel_calls=AUTOTUNE)\n",
    "                .batch(32)\n",
    "                .prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa8cc492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">visionary-morning-4</strong> at: <a href='https://wandb.ai/hectordavid55555211-test/test/runs/52wpoagg' target=\"_blank\">https://wandb.ai/hectordavid55555211-test/test/runs/52wpoagg</a><br> View project at: <a href='https://wandb.ai/hectordavid55555211-test/test' target=\"_blank\">https://wandb.ai/hectordavid55555211-test/test</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251130_212039-52wpoagg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\vpn\\Documents\\GitHub\\Ciencia-de-datos\\Conferencias\\wandb\\run-20251130_212319-zg16ji1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hectordavid55555211-test/test/runs/zg16ji1s' target=\"_blank\">celestial-star-5</a></strong> to <a href='https://wandb.ai/hectordavid55555211-test/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hectordavid55555211-test/test' target=\"_blank\">https://wandb.ai/hectordavid55555211-test/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hectordavid55555211-test/test/runs/zg16ji1s' target=\"_blank\">https://wandb.ai/hectordavid55555211-test/test/runs/zg16ji1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#inicializacion de wandb\n",
    "wandb.init(project=\"test\")\n",
    "config = wandb.config\n",
    "config.learning_rate = 1e-3\n",
    "config.batch_size = 32\n",
    "config.epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1ad33351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(224,224,3)),\n",
    "    tf.keras.layers.Conv2D(16,3,activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(config.learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3a6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_batch = next(iter(train_dataset))\n",
    "\n",
    "callbacks = [\n",
    "    WandbCallback(\n",
    "        save_model=False,\n",
    "        log_weights=True,\n",
    "        log_gradients=False,\n",
    "        log_evaluation=True,\n",
    "        training_data=train_batch,\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"ckpt_best.h5\", save_best_only=True, monitor=\"val_loss\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c603b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WandbCallback is unable to read validation_data from trainer and therefore cannot log validation data. Ensure Keras is properly patched by calling `from wandb.keras import WandbCallback` at the top of your script.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.8393 - accuracy: 0.6822 - val_loss: 0.5494 - val_accuracy: 0.7848\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.8393 - accuracy: 0.6822 - val_loss: 0.5494 - val_accuracy: 0.7848\n",
      "Epoch 2/20\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vpn\\Documents\\GitHub\\Ciencia-de-datos\\.venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689/689 [==============================] - 66s 96ms/step - loss: 0.4202 - accuracy: 0.8500 - val_loss: 0.4257 - val_accuracy: 0.8400\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.4202 - accuracy: 0.8500 - val_loss: 0.4257 - val_accuracy: 0.8400\n",
      "Epoch 3/20\n",
      "Epoch 3/20\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.3167 - accuracy: 0.8964 - val_loss: 0.4094 - val_accuracy: 0.8367\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.3167 - accuracy: 0.8964 - val_loss: 0.4094 - val_accuracy: 0.8367\n",
      "Epoch 4/20\n",
      "Epoch 4/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.2582 - accuracy: 0.9196 - val_loss: 0.4218 - val_accuracy: 0.8295\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.2582 - accuracy: 0.9196 - val_loss: 0.4218 - val_accuracy: 0.8295\n",
      "Epoch 5/20\n",
      "Epoch 5/20\n",
      "689/689 [==============================] - 69s 100ms/step - loss: 0.2129 - accuracy: 0.9374 - val_loss: 0.4880 - val_accuracy: 0.7903\n",
      "689/689 [==============================] - 69s 100ms/step - loss: 0.2129 - accuracy: 0.9374 - val_loss: 0.4880 - val_accuracy: 0.7903\n",
      "Epoch 6/20\n",
      "Epoch 6/20\n",
      "689/689 [==============================] - 68s 99ms/step - loss: 0.1818 - accuracy: 0.9486 - val_loss: 0.5432 - val_accuracy: 0.7729\n",
      "689/689 [==============================] - 68s 99ms/step - loss: 0.1818 - accuracy: 0.9486 - val_loss: 0.5432 - val_accuracy: 0.7729\n",
      "Epoch 7/20\n",
      "Epoch 7/20\n",
      "689/689 [==============================] - 68s 98ms/step - loss: 0.1497 - accuracy: 0.9592 - val_loss: 0.5854 - val_accuracy: 0.7761\n",
      "689/689 [==============================] - 68s 98ms/step - loss: 0.1497 - accuracy: 0.9592 - val_loss: 0.5854 - val_accuracy: 0.7761\n",
      "Epoch 8/20\n",
      "Epoch 8/20\n",
      "689/689 [==============================] - 68s 99ms/step - loss: 0.1313 - accuracy: 0.9670 - val_loss: 0.6489 - val_accuracy: 0.7707\n",
      "689/689 [==============================] - 68s 99ms/step - loss: 0.1313 - accuracy: 0.9670 - val_loss: 0.6489 - val_accuracy: 0.7707\n",
      "Epoch 9/20\n",
      "Epoch 9/20\n",
      "689/689 [==============================] - 69s 101ms/step - loss: 0.1037 - accuracy: 0.9751 - val_loss: 0.7160 - val_accuracy: 0.7790\n",
      "689/689 [==============================] - 69s 101ms/step - loss: 0.1037 - accuracy: 0.9751 - val_loss: 0.7160 - val_accuracy: 0.7790\n",
      "Epoch 10/20\n",
      "Epoch 10/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0947 - accuracy: 0.9797 - val_loss: 0.8296 - val_accuracy: 0.7496\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0947 - accuracy: 0.9797 - val_loss: 0.8296 - val_accuracy: 0.7496\n",
      "Epoch 11/20\n",
      "Epoch 11/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0792 - accuracy: 0.9850 - val_loss: 0.9217 - val_accuracy: 0.7358\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0792 - accuracy: 0.9850 - val_loss: 0.9217 - val_accuracy: 0.7358\n",
      "Epoch 12/20\n",
      "Epoch 12/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0701 - accuracy: 0.9876 - val_loss: 0.9129 - val_accuracy: 0.7732\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0701 - accuracy: 0.9876 - val_loss: 0.9129 - val_accuracy: 0.7732\n",
      "Epoch 13/20\n",
      "Epoch 13/20\n",
      "689/689 [==============================] - 67s 98ms/step - loss: 0.0592 - accuracy: 0.9902 - val_loss: 1.0874 - val_accuracy: 0.7424\n",
      "689/689 [==============================] - 67s 98ms/step - loss: 0.0592 - accuracy: 0.9902 - val_loss: 1.0874 - val_accuracy: 0.7424\n",
      "Epoch 14/20\n",
      "Epoch 14/20\n",
      "689/689 [==============================] - 67s 98ms/step - loss: 0.0596 - accuracy: 0.9894 - val_loss: 1.1802 - val_accuracy: 0.7242\n",
      "689/689 [==============================] - 67s 98ms/step - loss: 0.0596 - accuracy: 0.9894 - val_loss: 1.1802 - val_accuracy: 0.7242\n",
      "Epoch 15/20\n",
      "Epoch 15/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0513 - accuracy: 0.9906 - val_loss: 1.0657 - val_accuracy: 0.7700\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0513 - accuracy: 0.9906 - val_loss: 1.0657 - val_accuracy: 0.7700\n",
      "Epoch 16/20\n",
      "Epoch 16/20\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.0417 - accuracy: 0.9914 - val_loss: 1.3303 - val_accuracy: 0.7366\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.0417 - accuracy: 0.9914 - val_loss: 1.3303 - val_accuracy: 0.7366\n",
      "Epoch 17/20\n",
      "Epoch 17/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0347 - accuracy: 0.9946 - val_loss: 1.4628 - val_accuracy: 0.7010\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0347 - accuracy: 0.9946 - val_loss: 1.4628 - val_accuracy: 0.7010\n",
      "Epoch 18/20\n",
      "Epoch 18/20\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0336 - accuracy: 0.9946 - val_loss: 1.6740 - val_accuracy: 0.7072\n",
      "689/689 [==============================] - 67s 97ms/step - loss: 0.0336 - accuracy: 0.9946 - val_loss: 1.6740 - val_accuracy: 0.7072\n",
      "Epoch 19/20\n",
      "Epoch 19/20\n",
      "689/689 [==============================] - 67s 98ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 1.6045 - val_accuracy: 0.7264\n",
      "689/689 [==============================] - 67s 98ms/step - loss: 0.0391 - accuracy: 0.9912 - val_loss: 1.6045 - val_accuracy: 0.7264\n",
      "Epoch 20/20\n",
      "Epoch 20/20\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.0333 - accuracy: 0.9921 - val_loss: 1.7311 - val_accuracy: 0.7202\n",
      "689/689 [==============================] - 66s 96ms/step - loss: 0.0333 - accuracy: 0.9921 - val_loss: 1.7311 - val_accuracy: 0.7202\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=config.epochs,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd295e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▆▆▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▅██▇▅▅▅▅▅▃▃▅▃▂▄▃▁▁▂▂</td></tr><tr><td>val_loss</td><td>▂▁▁▁▁▂▂▂▃▃▄▄▅▅▄▆▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99211</td></tr><tr><td>best_epoch</td><td>2</td></tr><tr><td>best_val_loss</td><td>0.40944</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.03328</td></tr><tr><td>val_accuracy</td><td>0.72025</td></tr><tr><td>val_loss</td><td>1.73114</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">celestial-star-5</strong> at: <a href='https://wandb.ai/hectordavid55555211-test/test/runs/zg16ji1s' target=\"_blank\">https://wandb.ai/hectordavid55555211-test/test/runs/zg16ji1s</a><br> View project at: <a href='https://wandb.ai/hectordavid55555211-test/test' target=\"_blank\">https://wandb.ai/hectordavid55555211-test/test</a><br>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251130_212319-zg16ji1s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(\"model_final.h5\")\n",
    "artifact = wandb.Artifact(\"malaria-cnn-model\", type=\"model\")\n",
    "artifact.add_file(\"model_final.h5\")\n",
    "artifact.add_file(\"ckpt_best.h5\")\n",
    "wandb.log_artifact(artifact)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
